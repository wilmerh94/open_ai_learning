{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color palette Generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and using OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv\n",
    "# Creating a env on Windows\n",
    "# %echo> .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import dotenv_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "config = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "openai.api_key= config['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Completion text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "\n",
    "# Creating a env on Windows\n",
    "# %echo> .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key= config['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_colors(colors):\n",
    "    \"\"\"\n",
    "    Purpose: display 4 black block with the unicode on HTML to see the colors, and it will be join to one answer by the function .join\n",
    "    Markdown is called to be able to apply HTML\n",
    "    \"\"\"\n",
    "    display(Markdown(\" \".join(\n",
    "        f\"<span style='color: {color}'>{chr(9608) * 4}</span>\" # 9608 is a unicode for a black block\n",
    "        for color in colors\n",
    "    )))\n",
    "    # end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_render_colors(msg):\n",
    "    prompt = f\"\"\"\n",
    "    You are a color palette generating assistant that responds to text prompts for color palettes\n",
    "    Your should generate color palettes that fit the theme, mood, or instructions in the prompt.\n",
    "    The palettes should be between 2 and 8 colors.\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: The Mediterranean Sea\n",
    "    A: [\"#006699\", \"#66CCCC\", \"#F0E68C\", \"#008000\", \"#F08080\"]\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: sage, nature, earth\n",
    "    A: [\"#EDF1D6\", \"#9DC08B\", \"#609966\", \"#40513B\"]\n",
    "\n",
    "\n",
    "    Desired Format: a JSON array of hexadecimal color codes\n",
    "\n",
    "    Q: Convert the following verbal description of a color palette into a list of colors: {msg} \n",
    "    A:\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        model=\"text-davinci-003\",\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    colors = json.loads(response[\"choices\"][0][\"text\"])\n",
    "    display_colors(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TikToken for OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`With this library I can see how many token will be use so I can have a number of how much it will cost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# enc = tiktoken.get_encoding('p50k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(enc.encode('Hello world!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, model_name):\n",
    "    \"\"\"\n",
    "    Purpose: Returns the number of token in a text string.\n",
    "    the price per token is \n",
    "    GPT 3.5 Turbo\n",
    "    Model\t                Input\t            Output\n",
    "    4K context\t$0.0015 / 1K tokens\t$0.002 / 1K tokens\n",
    "    16K context\t$0.003 / 1K tokens\t$0.004 / 1K tokens\n",
    "    \n",
    "    \"\"\"\n",
    "    price_per_token = 0.002 / 1000\n",
    "    encoding= tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    print(num_tokens * price_per_token)\n",
    "    return num_tokens\n",
    "    \n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(book, 'gpt-3.5-turbo')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_json= \"\"\"\n",
    " [\n",
    "    {\"song\": \"Happy\", \"artist\": \"Pharrell Williams\"},\n",
    "    {\"song\": \"Can't Stop the Feeling!\", \"artist\": \"Justin Timberlake\"},\n",
    "    {\"song\": \"Uptown Funk\", \"artist\": \"Mark Ronson ft. Bruno Mars\"},\n",
    "    {\"song\": \"Shut Up and Dance\", \"artist\": \"Walk The Moon\"},\n",
    "    {\"song\": \"Don't Stop Me Now\", \"artist\": \"Queen\"},\n",
    "    {\"song\": \"24K Magic\", \"artist\": \"Bruno Mars\"},\n",
    "    {\"song\": \"Good Vibrations\", \"artist\": \"The Beach Boys\"},\n",
    "    {\"song\": \"I Wanna Dance with Somebody\", \"artist\": \"Whitney Houston\"},\n",
    "    {\"song\": \"Happy Together\", \"artist\": \"The Turtles\"},\n",
    "    {\"song\": \"Dancing Queen\", \"artist\": \"ABBA\"}\n",
    "]\n",
    "\"\"\"\n",
    "messages =[\n",
    "    { 'role':'system','content': \"\"\" You are a helpful playlist generating assistant.\n",
    "     You should generate a list off songs and their artists according to a text prompt\n",
    "     You should return a JSON array, where each element follow this format:\n",
    "     `{\"song\": <song_title>, \"artist\": <artist_name>}`\n",
    "     \"\"\"},\n",
    "     {\"role\":\"user\", \"content\":\"Generate a playlist of songs based on this prompt: super super hype happy songs\"},\n",
    "     {\"role\":\"system\", \"content\": example_json},\n",
    "     {\"role\":\"user\", \"content\":\"Generate a playlist of songs based on this prompt: hype high energy super happy songs\"},\n",
    "]\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    messages=messages,\n",
    "    model='gpt-3.5-turbo',\n",
    "    max_tokens=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\"song\": \"Can't Stop the Feeling!\", \"artist\": \"Justin Timberlake\"},\n",
      "    {\"song\": \"Happy\", \"artist\": \"Pharrell Williams\"},\n",
      "    {\"song\": \"Uptown Funk\", \"artist\": \"Mark Ronson ft. Bruno Mars\"},\n",
      "    {\"song\": \"Shut Up and Dance\", \"artist\": \"Walk The Moon\"},\n",
      "    {\"song\": \"24K Magic\", \"artist\": \"Bruno Mars\"},\n",
      "    {\"song\": \"Don't Stop Me Now\", \"artist\": \"Queen\"},\n",
      "    {\"song\": \"I Gotta Feeling\", \"artist\": \"The Black Eyed Peas\"},\n",
      "    {\"song\": \"Jump Around\", \"artist\": \"House of Pain\"},\n",
      "    {\"song\": \"Crazy in Love\", \"artist\": \"Beyonc√© ft. Jay-Z\"},\n",
      "    {\"song\": \"Dance Monkey\", \"artist\": \"Tones and I\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(res['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_playlist(prompt,count=20):\n",
    "    \"\"\"\n",
    "    Purpose: \n",
    "    \"\"\"\n",
    "    example_json= \"\"\"\n",
    "        [\n",
    "    {\"song\": \"Happy\", \"artist\": \"Pharrell Williams\"},\n",
    "    {\"song\": \"Can't Stop the Feeling!\", \"artist\": \"Justin Timberlake\"},\n",
    "    {\"song\": \"Uptown Funk\", \"artist\": \"Mark Ronson ft. Bruno Mars\"},\n",
    "    {\"song\": \"Shut Up and Dance\", \"artist\": \"Walk The Moon\"},\n",
    "    {\"song\": \"Don't Stop Me Now\", \"artist\": \"Queen\"},\n",
    "    {\"song\": \"24K Magic\", \"artist\": \"Bruno Mars\"},\n",
    "    {\"song\": \"Good Vibrations\", \"artist\": \"The Beach Boys\"},\n",
    "    {\"song\": \"I Wanna Dance with Somebody\", \"artist\": \"Whitney Houston\"},\n",
    "    {\"song\": \"Happy Together\", \"artist\": \"The Turtles\"},\n",
    "    {\"song\": \"Dancing Queen\", \"artist\": \"ABBA\"}\n",
    "        ]\n",
    "    \"\"\"\n",
    "    messages =[\n",
    "    { 'role':'system','content': \"\"\" You are a helpful playlist generating assistant.\n",
    "    You should generate a list off songs and their artists according to a text prompt\n",
    "    You should return a JSON array, where each element follow this format:\n",
    "    `{\"song\": <song_title>, \"artist\": <artist_name>}`\n",
    "    \"\"\"},\n",
    "    {\"role\":\"user\", \"content\": \"Generate a playlist of 10 songs based on this prompt: super super hype happy songs\"},\n",
    "    {\"role\":\"system\", \"content\": example_json},\n",
    "    {\"role\":\"user\", \"content\": f\"Generate a playlist of {count} songs based on this prompt: {prompt}\"},\n",
    "        ]\n",
    "    res = openai.ChatCompletion.create(\n",
    "    messages=messages,\n",
    "    model='gpt-3.5-turbo',\n",
    "    max_tokens=800\n",
    "        )\n",
    "    # return json.loads(res['choices'][0]['message']['content'])\n",
    "    # print(res['choices'][0]['message']['content'])\n",
    "    playlist = json.loads(res['choices'][0]['message']['content'])\n",
    "    print(playlist)\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\"song\": \"Don't Stop Me Now\", \"artist\": \"Queen\"},\n",
      "    {\"song\": \"Walking on Sunshine\", \"artist\": \"Katrina and The Waves\"},\n",
      "    {\"song\": \"I Want to Hold Your Hand\", \"artist\": \"The Beatles\"},\n",
      "    {\"song\": \"Good Vibrations\", \"artist\": \"The Beach Boys\"},\n",
      "    {\"song\": \"Mr. Blue Sky\", \"artist\": \"Electric Light Orchestra\"},\n",
      "    {\"song\": \"Happy Together\", \"artist\": \"The Turtles\"},\n",
      "    {\"song\": \"Lovely Day\", \"artist\": \"Bill Withers\"},\n",
      "    {\"song\": \"Can't Stop the Feeling!\", \"artist\": \"Justin Timberlake\"},\n",
      "    {\"song\": \"Three Little Birds\", \"artist\": \"Bob Marley & The Wailers\"},\n",
      "    {\"song\": \"I Will Survive\", \"artist\": \"Gloria Gaynor\"},\n",
      "    {\"song\": \"Hey Jude\", \"artist\": \"The Beatles\"},\n",
      "    {\"song\": \"Dancing Queen\", \"artist\": \"ABBA\"},\n",
      "    {\"song\": \"Beautiful Day\", \"artist\": \"U2\"},\n",
      "    {\"song\": \"Walking on Sunshine\", \"artist\": \"Katrina and The Waves\"},\n",
      "    {\"song\": \"Happy\", \"artist\": \"Pharrell Williams\"},\n",
      "    {\"song\": \"I Wanna Dance with Somebody\", \"artist\": \"Whitney Houston\"},\n",
      "    {\"song\": \"I Just Want to Celebrate\", \"artist\": \"Rare Earth\"},\n",
      "    {\"song\": \"Don't Stop Believin'\", \"artist\": \"Journey\"},\n",
      "    {\"song\": \"Can't Help Falling in Love\", \"artist\": \"Elvis Presley\"},\n",
      "    {\"song\": \"All You Need Is Love\", \"artist\": \"The Beatles\"},\n",
      "    {\"song\": \"What a Wonderful World\", \"artist\": \"Louis Armstrong\"},\n",
      "    {\"song\": \"Lovely Day\", \"artist\": \"Bill Withers\"},\n",
      "    {\"song\": \"Happy\", \"artist\": \"Pharrell Williams\"},\n",
      "    {\"song\": \"Don't Stop Me Now\", \"artist\": \"Queen\"},\n",
      "    {\"song\": \"I Want to Hold Your Hand\", \"artist\": \"The Beatles\"},\n",
      "    {\"song\": \"Mr. Blue Sky\", \"artist\": \"Electric Light Orchestra\"},\n",
      "    {\"song\": \"Good Vibrations\", \"artist\": \"The Beach Boys\"},\n",
      "    {\"song\": \"Hey Jude\", \"artist\": \"The Beatles\"},\n",
      "    {\"song\": \"I Will Survive\", \"artist\": \"Gloria Gaynor\"},\n",
      "    {\"song\": \"What a Wonderful World\", \"artist\": \"Louis Armstrong\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "get_playlist('songs for happy heart',30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format='Desired Format: <comma_separeted _list_of_names>'\n",
    "# format='Desired Format: JSON array of place names'\n",
    "# format='Classify the following texts sentiment as positive, neutral and negative. Desired Format: a number. -1 for negative, 0 for neutral and 1 for positive'\n",
    "# format= 'Desired Format: JSON object with name as the key and value as value'\n",
    "# input='X. Answer: ... Let`s think step by step:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.Completion.create(\n",
    "#     model='davinci',\n",
    "#     prompt='Where can I learn cyber security perfectly',\n",
    "#     max_tokens=200,\n",
    "#     stop='11.'\n",
    "# )\n",
    "# # response\n",
    "# print(response['choices'][0]['text'])\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt= \"\"\"\n",
    "# you are a chatobot that speakss like a toddler.\n",
    "# User: Hi, how are you?\n",
    "# Chatbot:I'm good\n",
    "# User: Tell me about your family\n",
    "# Chatbot: I have a mommy and daddy and a baby sister and two cats\n",
    "# User: What do you do for fun?\n",
    "# Chatbot: I like to play outside, go to the park, and color.\n",
    "# User: \"That sounds fun. What colors do you like to use?\n",
    "# Chatbot:I like to use a lot of bright colors like pink, purple, yellow, and blue!\",\n",
    "# User:\n",
    "# \"\"\"\n",
    "# response = openai.Completion.create(\n",
    "#     model='text-davinci-003',\n",
    "#     prompt=prompt,\n",
    "#     max_tokens=200,\n",
    "#     # stop='11.'\n",
    "#     stop=['Chatbot:', 'User:'],\n",
    "#     # n=3 # how many answers i want\n",
    "#     echo = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Image.create_edit(\n",
    "  image=open(\"sunlit_lounge.png\", \"rb\"),\n",
    "  mask=open(\"mask.png\", \"rb\"),\n",
    "  prompt=\"A sunlit indoor lounge area with a pool containing a flamingo\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "image_url = response['data'][0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-ZFEKGsvFxcLxdgWSOIN215LG/user-NgNV5VbwSJjJYy8EoDDk3Krf/img-vDxExSHq8kamPRlUGMciP77E.png?st=2023-07-05T18%3A55%3A34Z&se=2023-07-05T20%3A55%3A34Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-07-04T20%3A32%3A26Z&ske=2023-07-05T20%3A32%3A26Z&sks=b&skv=2021-08-06&sig=BS0zg1y7WvyIqM04%2BHdBldI%2BZNJgXOFNcwWOSP44jGQ%3D'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-ZFEKGsvFxcLxdgWSOIN215LG/user-NgNV5VbwSJjJYy8EoDDk3Krf/img-vDxExSHq8kamPRlUGMciP77E.png?st=2023-07-05T18%3A55%3A34Z&se=2023-07-05T20%3A55%3A34Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-07-04T20%3A32%3A26Z&ske=2023-07-05T20%3A32%3A26Z&sks=b&skv=2021-08-06&sig=BS0zg1y7WvyIqM04%2BHdBldI%2BZNJgXOFNcwWOSP44jGQ%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=image_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports:\n",
    "- It is good to see that the imports are separated by line.\n",
    "- However, it is better to organize the imports in a more logical order. For example, first import standard library modules, then third-party modules, and finally local modules.\n",
    "- Additionally, it is recommended to use explicit imports instead of using '*' to import all contents from a module. This helps in better understanding of which modules/functions are being used in the code.\n",
    "- Consider adding whitespace between the imports for better readability.\n",
    "\n",
    "Here's an improved version of the imports section:\n",
    "```python\n",
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "```\n",
    "\n",
    "2. Constants:\n",
    "- It is good practice to write constants in uppercase with underscores as separators.\n",
    "- Consider renaming the `MODEL` constant to `MODEL_NAME` for clarity.\n",
    "- It is better to avoid hardcoding the model name as a string in the code. Instead, consider storing it in a configuration file or environment variable.\n",
    "\n",
    "Here's an improved version of the constants section:\n",
    "```python\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "```\n",
    "\n",
    "3. Variable Naming:\n",
    "- The variable name `INFORMATION` is quite vague and doesn't provide meaningful information about its purpose. Consider using a more descriptive name, such as `PERSON_INFO`.\n",
    "\n",
    "4. Main Function:\n",
    "- The code inside the `if __name__ == \"__main__\":` block should be wrapped in a function to improve modularity and allow for better testing.\n",
    "- The print statement `\"Hello\"` doesn't serve any useful purpose here and can be removed.\n",
    "\n",
    "5. Template String Formatting:\n",
    "- The SUMMARY_TEMPLATE contains unnecessary indentation. It should be removed for better readability.\n",
    "\n",
    "Here's an improved version of the SUMMARY_TEMPLATE:\n",
    "```python\n",
    "SUMMARY_TEMPLATE = \"\"\"\n",
    "Given the information {information} about a person from I want you to create:\n",
    "1. Short Summary\n",
    "2. Two interesting facts about them\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "6. Class Instantiation:\n",
    "- It is good to see that the `PromptTemplate` and `ChatOpenAI` classes are instantiated with keyword arguments. This makes the code more readable and maintainable.\n",
    "\n",
    "7. Line Length:\n",
    "- The line length of some lines in the code exceeds the recommended limit of 79 characters. Consider breaking long lines into multiple lines for better readability.\n",
    "\n",
    "8. Documentation:\n",
    "- It would be helpful to add some comments or docstrings to explain the purpose of the code and any complex logic.\n",
    "\n",
    "Overall, the code follows basic coding style guidelines but there are some areas that can be improved for \n",
    "better style, readability, and maintainability. The code would benefit from better organization of imports, more descriptive variable names, and improved modularity. Additionally, it would be beneficial to add comments or docstrings to explain the purpose of the code. If possible, consider storing the model name in a configuration file or environment variable for better flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
